---
title: "multistream_alignment"
format: html
---

```{r}
library(tidyverse)
library(here)
library(glue)

theme_set(theme_bw() +
            theme(strip.background = element_blank(),
                  panel.grid = element_blank()))
```

```{r}
OBJECTS_LOC = here("data", "frame_data", "cdi_allframes_1fps")
INTERMEDIATES_LOC = here("intermediates")

df_locs <- read_csv(here(INTERMEDIATES_LOC, "merged_locations.csv"))
df_trans <- read_csv(here(INTERMEDIATES_LOC, "merged_trans_annotated.csv"))
df_pose <- read_csv(here(INTERMEDIATES_LOC, "4M_with_NA_bbox_limbs.csv"))
all_vids <- df_locs |> 
  pull(superseded_gcp_name_feb25) |> 
  unique()
```

# Video summary
Counting objects and tokens to choose annotations
```{r}
get_counts <- function(video_id) {
  vid_obj <- read_csv(here(OBJECTS_LOC, glue("{video_id}_processed"), "bounding_box_predictions.csv"),
                      show_col_types = FALSE)
  vid_trans <- df_trans |> 
    filter(superseded_gcp_name_feb25 == video_id)
  vid_locs <- df_locs |> 
    filter(superseded_gcp_name_feb25 == video_id)
  
  obj_sum <- vid_obj |> 
    group_by(class_name) |> 
    summarise(frames_with_object = n()) |>
    rename(annotation = class_name)
  
  tok_sum <- vid_trans |> 
    group_by(token) |> 
    summarise(token_count = n()) |> 
    rename(annotation = token)
  
  loc_sum <- vid_locs |> 
    group_by(locations_avg) |> 
    summarise(location_count = n()) |>
    rename(annotation = locations_avg)
  
  full_sum <- full_join(obj_sum, tok_sum, by = join_by(annotation)) |> 
    full_join(loc_sum, by = join_by(annotation))
  
  full_sum
}
```

```{r}
test_id <- "00220001_2024-02-05_2_e0769ef060"
test_counts <- get_counts(test_id)
```

# Combine annotations
```{r}
bind_annotations <- function(video_id,
                             objects = "random",
                             tokens = "random",
                             k = 5, threshold = 5) {
  vid_summary <- get_counts(video_id)
  # if random, make choices
  if (length(objects) == 1 && objects == "random") {
    objects <- vid_summary |> 
      filter(!is.na(frames_with_object),
             frames_with_object >= threshold,
             !annotation %in% c("hand", "face")) |>
      sample_n(k) |> 
      pull(annotation)
  }
  if (length(tokens) == 1 && tokens == "random") {
    tokens <- vid_summary |> 
      filter(!is.na(token_count),
             token_count >= threshold) |>
      sample_n(k) |> 
      pull(annotation)
  }
  
  # objects
  vid_obj <- read_csv(here(OBJECTS_LOC, glue("{video_id}_processed"), "bounding_box_predictions.csv"),
                      show_col_types = FALSE)
  vid_obj_cleaned <- vid_obj |> 
    select(superseded_gcp_name_feb25, timestamp = frame_id, annotation = class_name) |>
    filter(annotation %in% objects) |> 
    mutate(stream = "objects",
           timestamp = as.numeric(timestamp))
  
  # speech
  vid_trans <- df_trans |> 
    filter(superseded_gcp_name_feb25 == video_id)
  vid_speech_cleaned <- tibble(
    superseded_gcp_name_feb25 = video_id,
    timestamp = vid_obj$frame_id |> as.numeric(),
    stream = "speech"
  ) |> left_join(vid_trans |> 
                   select(superseded_gcp_name_feb25, token_start_time, token_end_time, token) |>
                   mutate(token_start_time = as.numeric(token_start_time),
                          token_end_time = as.numeric(token_end_time)), 
                 by = join_by(superseded_gcp_name_feb25,
                              timestamp >= token_start_time, 
                              timestamp <= token_end_time)) |> 
    distinct() |> 
    mutate(speech = ifelse(!is.na(token), "all speech", NA) |> as.character()) |> 
    filter(!is.na(speech)) |> 
    pivot_longer(cols = c(token, speech),
                 names_to = "type",
                 values_to = "annotation") |> 
    filter(annotation %in% c("all speech", tokens)) |> 
    select(-type, -token_start_time, -token_end_time)
  
  # locations
  vid_locs <- df_locs |> 
    filter(superseded_gcp_name_feb25 == video_id)
  vid_locs_cleaned <- vid_locs |> 
    select(superseded_gcp_name_feb25, timestamp = frame_num, annotation = locations_avg) |>
    mutate(stream = "locations",
           timestamp = as.numeric(timestamp))
  
  # pose
  vid_pose <- df_pose |>
    filter(superseded_gcp_name_feb25 == video_id)
  vid_pose_cleaned <- vid_pose |> 
    select(superseded_gcp_name_feb25, timestamp = time_in_extended_iso, 
           face = face_in_image, lh = left_hand_in_image, rh = right_hand_in_image) |>
    mutate(stream = "pose",
           timestamp = as.numeric(timestamp),
           hand = pmin(1, lh + rh)) |> 
    pivot_longer(cols = c(face, hand),
                 names_to = "annotation",
                 values_to = "annotation_value") |> 
    filter(annotation_value == 1) |> 
    arrange(timestamp) |> 
    select(-lh, -rh, -annotation_value) |> 
    distinct()
  
  # combine
  vid_full <- list(vid_obj_cleaned,
                   vid_locs_cleaned,
                   vid_speech_cleaned,
                   vid_pose_cleaned) |> 
    list_rbind()
}
```

```{r}
test_full <- bind_annotations(test_id,
                              objects = c("table", "plate", "chair", "bowl", "apple"),
                              tokens = c("you", "want", "more", "the", "banana"))
```

# Plot!
```{r}
STREAM_COLORS <- c("Objects" = "#e06666",
                   "Pose" = "#f6b26b",
                   "Locations" = "#93c47d",
                   "Speech" = "#76a5af")

make_kosie_plot <- function(full_annotations) {
  full_annotations |> 
    mutate(stream = str_to_sentence(stream),
           annotation = annotation |> fct_infreq() |> fct_rev()) |> 
    ggplot(aes(x = timestamp,
               y = annotation,
               fill = stream)) +
    geom_tile(width = 1, height = 1) +
    facet_grid(stream ~ .,
               scales = "free_y",
               space = "free_y") +
    labs(x = "Time (s)",
         y = "Annotation") +
    scale_fill_manual(values = STREAM_COLORS) +
    theme(legend.position = "none")
}

make_kosie_plot(test_full)
```

```{r}
make_kosie_plot(bind_annotations(all_vids[203]))
```

```{r}
make_kosie_plot(bind_annotations("00370002_2024-04-14_3_14a09138ad"))
```

```{r}
df_loc_switches <- df_locs |> 
  group_by(superseded_gcp_name_feb25) |> 
  mutate(is_switch = ifelse(location != lag(location), 1, 0)) |>
  summarise(num_switches = sum(is_switch, na.rm = TRUE))
```

- Harmonic mean over location probabilities
- See whether different locations vary in terms of their object distribution entropies
- See whether different locations vary in terms of their token distributions entropies
- Try different thresholds for word frequency before getting keyness?
- Look at relationship between word frequency and Whisper accuracy on val set




More location cleaning, just trying out
```{r}
library(zoo)
WIDTH = 60
df_locs_cleaned <- df_locs |> 
  group_by(superseded_gcp_name_feb25) |>
  mutate(locations_avg = rollapply(location, width = WIDTH,
                                   FUN = \(x) {
                                     ux <- unique(x)
                                     ux <- ux[!is.na(ux)]
                                     counts <- tabulate(match(x, ux))
                                     # break ties by favouring middle
                                     counts[which(ux == x[ceiling((WIDTH+1)/2)])] <- 
                                       counts[which(ux == x[ceiling((WIDTH+1)/2)])] + 0.5
                                     ux[which.max(counts)]
                                   },
                                   partial = TRUE))
```

